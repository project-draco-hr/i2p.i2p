{
  ReusableGZIPInputStream _in=null;
  long written=0;
  ByteArray ba=null;
  try {
    _in=ReusableGZIPInputStream.acquire();
    _in.initialize(_inRaw);
    ba=_cache.acquire();
    byte buf[]=ba.getData();
    int read=-1;
    while ((read=_in.read(buf)) != -1) {
      if (_log.shouldLog(Log.DEBUG))       _log.debug("Read " + read + " and writing it to the browser/streams");
      _out.write(buf,0,read);
      _out.flush();
      written+=read;
    }
    if (_log.shouldLog(Log.INFO))     _log.info("Decompressed: " + written + ", "+ _in.getTotalRead()+ "/"+ _in.getTotalExpanded());
  }
 catch (  IOException ioe) {
    if (_log.shouldLog(Log.WARN))     _log.warn("Error decompressing: " + written + ", "+ (_in != null ? _in.getTotalRead() + "/" + _in.getTotalExpanded() : ""),ioe);
  }
catch (  OutOfMemoryError oom) {
    _log.error("OOM in HTTP Decompressor",oom);
  }
 finally {
    if (_log.shouldLog(Log.INFO) && (_in != null))     _log.info("After decompression, written=" + written + " read="+ _in.getTotalRead()+ ", expanded="+ _in.getTotalExpanded()+ ", remaining="+ _in.getRemaining()+ ", finished="+ _in.getFinished());
    if (ba != null)     _cache.release(ba);
    if (_out != null)     try {
      _out.close();
    }
 catch (    IOException ioe) {
    }
  }
  if (_in != null) {
    double compressed=_in.getTotalRead();
    double expanded=_in.getTotalExpanded();
    ReusableGZIPInputStream.release(_in);
    if (compressed > 0 && expanded > 0) {
      double ratio=compressed / expanded;
      _context.statManager().addRateData("i2ptunnel.httpCompressionRatio",(int)(100d * ratio),0);
      _context.statManager().addRateData("i2ptunnel.httpCompressed",(long)compressed,0);
      _context.statManager().addRateData("i2ptunnel.httpExpanded",(long)expanded,0);
    }
  }
}
