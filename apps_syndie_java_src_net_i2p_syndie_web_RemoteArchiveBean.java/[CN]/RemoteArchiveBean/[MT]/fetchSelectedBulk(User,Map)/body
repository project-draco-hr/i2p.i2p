{
  String entries[]=ArchiveViewerBean.getStrings(parameters,"entry");
  String action=ArchiveViewerBean.getString(parameters,"action");
  if ("Fetch all new entries".equals(action)) {
    ArchiveIndex localIndex=BlogManager.instance().getArchive().getIndex();
    List uris=new ArrayList();
    List matches=new ArrayList();
    for (Iterator iter=_remoteIndex.getUniqueBlogs().iterator(); iter.hasNext(); ) {
      Hash blog=(Hash)iter.next();
      if (ignoreBlog(user,blog))       continue;
      _remoteIndex.selectMatchesOrderByEntryId(matches,blog,null);
      for (int i=0; i < matches.size(); i++) {
        BlogURI uri=(BlogURI)matches.get(i);
        if (!localIndex.getEntryIsKnown(uri))         uris.add(uri);
      }
      matches.clear();
    }
    entries=new String[uris.size()];
    for (int i=0; i < uris.size(); i++)     entries[i]=((BlogURI)uris.get(i)).toString();
  }
  if ((entries == null) || (entries.length <= 0))   return;
  if (_exportCapable) {
    StringBuffer url=new StringBuffer(512);
    url.append(buildExportURL());
    StringBuffer postData=new StringBuffer(512);
    Set meta=new HashSet();
    for (int i=0; i < entries.length; i++) {
      BlogURI uri=new BlogURI(entries[i]);
      if (uri.getEntryId() >= 0) {
        postData.append("entry=").append(uri.toString()).append('&');
        meta.add(uri.getKeyHash());
        _statusMessages.add("Scheduling bulk blog post fetch of " + HTMLRenderer.sanitizeString(entries[i]));
      }
    }
    for (Iterator iter=meta.iterator(); iter.hasNext(); ) {
      Hash blog=(Hash)iter.next();
      postData.append("meta=").append(blog.toBase64()).append('&');
      _statusMessages.add("Scheduling bulk blog metadata fetch of " + blog.toBase64());
    }
    try {
      File tmp=File.createTempFile("fetchBulk",".zip",BlogManager.instance().getTempDir());
      boolean shouldProxy=(_proxyHost != null) && (_proxyPort > 0);
      EepGet get=new EepGet(_context,shouldProxy,_proxyHost,_proxyPort,0,tmp.getAbsolutePath(),url.toString(),postData.toString());
      get.addStatusListener(new BulkFetchListener(tmp));
      get.fetch();
    }
 catch (    IOException ioe) {
      _statusMessages.add("Internal error creating temporary file to fetch " + HTMLRenderer.sanitizeString(url.toString()) + ": "+ ioe.getMessage());
    }
  }
 else {
    List urls=new ArrayList(entries.length + 8);
    for (int i=0; i < entries.length; i++) {
      BlogURI uri=new BlogURI(entries[i]);
      if (uri.getEntryId() >= 0) {
        String metaURL=buildMetaURL(uri.getKeyHash());
        if (!urls.contains(metaURL)) {
          urls.add(metaURL);
          _statusMessages.add("Scheduling blog metadata fetch of " + HTMLRenderer.sanitizeString(entries[i]));
        }
        urls.add(buildEntryURL(uri));
        _statusMessages.add("Scheduling blog post fetch of " + HTMLRenderer.sanitizeString(entries[i]));
      }
    }
    List tmpFiles=new ArrayList(1);
    try {
      for (int i=0; i < urls.size(); i++) {
        File t=File.createTempFile("fetchBulk",".dat",BlogManager.instance().getTempDir());
        tmpFiles.add(t);
      }
      fetch(urls,tmpFiles,user,new BlogStatusListener());
    }
 catch (    IOException ioe) {
      _statusMessages.add("Internal error creating temporary file to fetch posts: " + HTMLRenderer.sanitizeString(urls.toString()));
    }
  }
}
