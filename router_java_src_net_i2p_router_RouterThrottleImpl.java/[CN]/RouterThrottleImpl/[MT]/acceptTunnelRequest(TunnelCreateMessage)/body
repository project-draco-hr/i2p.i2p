{
  long lag=_context.jobQueue().getMaxLag();
  RateStat rs=_context.statManager().getRate("router.throttleNetworkCause");
  Rate r=null;
  if (rs != null)   r=rs.getRate(10 * 60 * 1000);
  long throttleEvents=(r != null ? r.getCurrentEventCount() + r.getLastEventCount() : 0);
  if (throttleEvents > THROTTLE_EVENT_LIMIT) {
    if (_log.shouldLog(Log.DEBUG))     _log.debug("Refusing tunnel request with the job lag of " + lag + " since there have been "+ throttleEvents+ " throttle events in the last 15 minutes or so");
    _context.statManager().addRateData("router.throttleTunnelCause",lag,lag);
    return false;
  }
  rs=_context.statManager().getRate("tunnel.participatingMessagesProcessed");
  r=null;
  if (rs != null)   r=rs.getRate(10 * 60 * 1000);
  double msgsPerTunnel=(r != null ? r.getAverageValue() : 0);
  r=null;
  rs=_context.statManager().getRate("tunnel.relayMessageSize");
  if (rs != null)   r=rs.getRate(10 * 60 * 1000);
  double bytesPerMsg=(r != null ? r.getAverageValue() : 0);
  double bytesPerTunnel=msgsPerTunnel * bytesPerMsg;
  int numTunnels=_context.tunnelManager().getParticipatingCount();
  double bytesAllocated=(numTunnels + 1) * bytesPerTunnel;
  _context.statManager().addRateData("tunnel.bytesAllocatedAtAccept",(long)bytesAllocated,msg.getTunnelDurationSeconds() * 1000);
  if (_log.shouldLog(Log.DEBUG))   _log.debug("Accepting a new tunnel request (now allocating " + bytesAllocated + " bytes across "+ numTunnels+ " tunnels with lag of "+ lag+ " and "+ throttleEvents+ " throttle events)");
  return true;
}
