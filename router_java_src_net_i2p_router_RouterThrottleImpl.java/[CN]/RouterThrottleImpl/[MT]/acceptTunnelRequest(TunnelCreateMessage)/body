{
  long lag=_context.jobQueue().getMaxLag();
  Rate throttleRate=_context.statManager().getRate("router.throttleNetworkCause").getRate(10 * 60 * 1000);
  long throttleEvents=throttleRate.getCurrentEventCount() + throttleRate.getLastEventCount();
  if (throttleEvents > THROTTLE_EVENT_LIMIT) {
    if (_log.shouldLog(Log.DEBUG))     _log.debug("Refusing tunnel request with the job lag of " + lag + " since there have been "+ throttleEvents+ " throttle events in the last 15 minutes or so");
    _context.statManager().addRateData("router.throttleTunnelCause",lag,lag);
    return false;
  }
  double msgsPerTunnel=_context.statManager().getRate("tunnel.participatingMessagesProcessed").getRate(10 * 60 * 1000).getAverageValue();
  double bytesPerMsg=_context.statManager().getRate("tunnel.relayMessageSize").getRate(10 * 60 * 1000).getAverageValue();
  double bytesPerTunnel=msgsPerTunnel * bytesPerMsg;
  int numTunnels=_context.tunnelManager().getParticipatingCount();
  double bytesAllocated=(numTunnels + 1) * bytesPerTunnel;
  _context.statManager().addRateData("tunnel.bytesAllocatedAtAccept",(long)bytesAllocated,msg.getTunnelDurationSeconds() * 1000);
  if (_log.shouldLog(Log.DEBUG))   _log.debug("Accepting a new tunnel request (now allocating " + bytesAllocated + " bytes across "+ numTunnels+ " tunnels with lag of "+ lag+ " and "+ throttleEvents+ " throttle events)");
  return true;
}
